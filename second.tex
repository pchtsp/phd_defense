\section{\secondtitle}
\input{graphs/solution_func.tikz}

\begin{frame}
  % \scriptsize
\frametitle{\textbf{Predicting learned-cuts}}
 
  \onslide<1->{
  % \begin{block}{Given an optimization problem}
  %   \begin{equation*}
  %     y^{*}(x) :\equiv arg \,\,\min_{y \in \mathcal{Y}(x)} C(x,y)
  %   \end{equation*}
  % \end{block}
  \begin{columns}[c]
    \column{0.5\linewidth}
    \textbf{An optimization problem}
    \column{0.5\linewidth}
    \begin{equation*}
      y^{*}(x) :\equiv arg \,\,\min_{y \in \mathcal{Y}(x)} C(x,y)
    \end{equation*}
  \end{columns}
  }
  \onslide<2->{
  \begin{columns}[c]
    \column{0.5\linewidth}
    \textbf{We obtain $\mathcal{N}$ solution features}
    \column{0.5\linewidth}
    \begin{equation*}
      g_n(y) \,\, \forall n \in \mathcal{N}
    \end{equation*}
  \end{columns}
  }
  \only<1->{
   \begin{adjustbox}{max totalsize={.5\textwidth}{.5\textheight},center}
      \DrawSolution{none}{none}{0}
   \end{adjustbox}
  }
\end{frame}

\begin{frame}
\frametitle{\textbf{Applying learned-cuts}}
  \onslide<1->{
  \begin{columns}[c]
    \column{0.6\linewidth}
    \textbf{We predict the optimal features}
    \column{0.4\linewidth}
    \begin{equation*}
      \hat{g}_n(x) \approx g_n(y^{*}) \,\, \forall n \in \mathcal{N}
    \end{equation*}
  \end{columns}
  }
  \onslide<2->{
  \begin{columns}[c]
    \column{0.6\linewidth}
    \textbf{We predict the optimal "zone"}
    \column{0.4\linewidth}
    \begin{align*}
      & \mathcal{Y}^\prime(x) = \{y \in \mathcal{Y} \mid  \\
      & \hspace{0.5cm} \hat{g}_n(x) = g_n(y) \,\, \forall n \in \mathcal{N}
      \}
    \end{align*}
  \end{columns}
  }
  \onslide<3->{
  \begin{columns}[c]
    \column{0.6\linewidth}
    \textbf{We solve the predicted model}
    \column{0.4\linewidth}
    \begin{equation*}
      \hat{y}^{*}(x) :\equiv arg \,\,\min_{y \in \mathcal{Y}^\prime(x)} C(x,y)          
    \end{equation*}
  \end{columns}
  }
  \only<1>{
   \begin{adjustbox}{max totalsize={.5\textwidth}{.5\textheight},center}
      \DrawSolution{blue}{none}{0}
   \end{adjustbox}
  }
  \only<2>{
   \begin{adjustbox}{max totalsize={.5\textwidth}{.5\textheight},center}
      \DrawSolution{blue}{north west lines}{0}
   \end{adjustbox}
   }
  \onslide<3->{
   \begin{adjustbox}{max totalsize={.5\textwidth}{.5\textheight},center}
      \DrawSolution{blue}{north west lines}{1}
   \end{adjustbox}
   }
\end{frame}

\begin{frame}
\frametitle{\textbf{Optimality of learned-cuts}}

  \begin{columns}[c]
    \column{0.6\linewidth}
    \textbf{With some (hopefully small) loss :}
    \column{0.4\linewidth}
    \begin{equation*}
      C(x,\hat{y}^{*}(x)) \approx  C(x,y^{*}(x))
    \end{equation*}
  \end{columns}
  \only<1>{
   \begin{adjustbox}{max totalsize={.5\textwidth}{.5\textheight},center}
      \DrawSolution{blue}{north west lines}{1}
   \end{adjustbox}
   }
  \only<2->{
   \begin{adjustbox}{max totalsize={.5\textwidth}{.5\textheight},center}
      \DrawSolution{blue}{north west lines}{2}
   \end{adjustbox}
   }
\end{frame}

\begin{frame}
\frametitle{\textbf{Why learned-cuts}}

  \begin{enumerate}[<+->]

  \item
    \textbf{Performance}: a smaller model is easier to solve.
  \item
    \textbf{User feedback}: direct feedback about the solution without
    needing to solve any model.
  \item
    \textbf{More stable solutions}: Every aircraft flies an amount that is
    closest to the mean of the fleet.
  \end{enumerate}
\end{frame}

\begin{frame}
\frametitle{\textbf{New formulation}}

  \begin{tabular}{p{5mm}p{90mm}}
    $a_{ijtt'}$ & : aircraft $i$ is in mission $j$ between $t$ and $t'$.  \\
    $m_{ip}$ &: aircraft $i$ uses check pattern $p$. \\
  \end{tabular}

  \onslide<1->{
    \input{graphs/gantt_example_check}
  }

  \onslide<2->{
    \begin{align}
      & \sum_{(j, t, t') \in \mathcal{J}\mathcal{T}\mathcal{T}_{ic}} a_{ijtt'} H^\prime_{jtt'} + U^{\prime}_{tc} \leq H^{M} + bigM (1 - m_{ip}) & \notag \\
      & \hspace{200px}  i \in \mathcal{I}, p \in \mathcal{P}, c \in \mathcal{C}_p \notag
    \end{align}
  }

\end{frame}

% \begin{frame}

%   \begin{block}{Formulation}

%   \begin{align}
%     & \text{Max}\;
%     \sum_{i \in \mathcal{I}, p \in \mathcal{P}} m_{ip} \times W_p \\
%     & \sum_{i \in \mathcal{I}, p \in \mathcal{P}_{t}} m_{ip} \leq C^{max} 
%             & t \in \mathcal{T} \label{eq:capacity1}\\
%     & \sum_{i \in \mathcal{I}_j, (t_1, t_2) \in \mathcal{T}_{jt}} a_{ijt_1t_2} \geq R_j
%             & j \in \mathcal{J}, t \in \mathcal{TJ}_j  \label{eq:missionres}\\
%     & \sum_{p \in \mathcal{P}_{t}} m_{ip} + \sum_{j \in \mathcal{J}_t \cap \mathcal{J}_i} \sum_{(t_1, t_2) \in \mathcal{T}_{jt}} a_{ijt_1t_2} \leq 1 
%             & t \in \mathcal{T}, i \in \mathcal{I} \label{eq:state}\\
%     & \sum_{(j, t, t') \in \mathcal{J}\mathcal{T}\mathcal{T}_{ic}} a_{ijtt'} H^\prime_{jtt'} + U^{\prime}_{tc} \leq H^M + M (1 - m_{ip}) & \notag \\
%       & & i \in \mathcal{I}, p \in \mathcal{P}, c \in \mathcal{C}_p \\
%   \end{align}

%   \end{block}

% \end{frame}

% \begin{frame}
%   \begin{block}{New vs old formulation}

%   \begin{enumerate}[<+->]

%   \item
%     It uses 3 times the number of constraints and 3 times the number of
%     variables.
%   \end{enumerate}

%   \begin{itemize}[<+->]

%   \item
%     variables: 11000 =\textgreater{} 28000.
%   \item
%     constraints: 13000 =\textgreater{} 48000.
%   \end{itemize}

%   \begin{enumerate}[<+->]

%   \item
%     It is still better. Better lineal relaxation, better performance.
%   \item
%     Can we reduce intelligently the number of variables?
%   \end{enumerate}

%   \begin{itemize}[<+->]

%   \item
%     we can.
%   \end{itemize}

%   \end{block}

% \end{frame}

\begin{frame}
\frametitle{\textbf{Distance between maintenances}}

  For each aircraft $i$: $D_i(y) \in [E^{min},E^{max}] \,\, \forall y \in \mathcal{Y}(x)$. \\
  \only<2>{
  \input{graphs/gantt_example_distance}
  }
  % \only<2>{
  % \input{graphs/gantt_example_distance}
  % }
  \only<3->{
  Solution feature: $g_1(y) = \mu_{t'-t} = \frac {\sum_{i \in \mathcal{I}} D_i(y)}{I}$. \\
  }
  \only<4->{
  Distribution of $\mu^*_{t'-t}$: \\
  \includegraphics[height=0.4\linewidth]{hist_mean_dist_complete_IT000125_20190716}
  }

\end{frame}

\begin{frame}
\frametitle{\textbf{Solution feature prediction}}

  \begin{block}{\textbf{Technique}}
    Quantile regressions: upper bound and lower bound.
  \end{block}

  \begin{block}{\textbf{Training set}}
    of 5000 small instances solved to optimal.
  \end{block}

  \begin{block}{\textbf{Input features}}
    ...
  \end{block}

  \begin{block}{\textbf{Solution features}}
    \begin{equation*}
      \mu_{t'-t} \to [\hat{\mu}_{t'-t}^{lb}, \hat{\mu}_{t'-t}^{ub}]
   \end{equation*}
  \end{block}

  % \emph{} to estimate upper and lower bounds. 
  % * \textbf{Training}: 5000 small instances. 
  % * \textbf{Input features}: 
  %   * mean flight demand per period, 
  %   * total remaining flight hours at start (init), 
  %   * variance of flight demand, 
  %   * demand of special missions, 
  %   * number of period where flight demand is cut in two. 
  % TODO: add prediction results
  % TODO: add prediction example
\end{frame}

\begin{frame}
\frametitle{\textbf{Applying learned-cuts}}

  \begin{block}{\textbf{Pattern filtering:}}
    \begin{equation*}
      D_{ip} \in [\hat{\mu}_{t'-t}^{lb} - tol, \hat{\mu}_{t'-t}^{ub} + tol] \rightarrow p \in \mathcal{P}_i 
    \end{equation*}
  \end{block}

  \begin{block}{\textbf{Pattern recycling:} with probabiliy $\alpha$}
    \begin{equation*}
      D_{ip} \notin [\hat{\mu}_{t'-t}^{lb} - tol, \hat{\mu}_{t'-t}^{ub} + tol] \land P(\alpha)  \rightarrow p \in \mathcal{P}_i 
    \end{equation*}
  \end{block}


\end{frame}

\begin{frame}

\begin{block}{Experiments}

\begin{itemize}[<+->]

\item
  Number of instances: medium (1000), large (1000) and very large
  (1000).
\item Time limit at 3600 seconds.
\item We seeded instance generation for better comparison.
\item CPLEX running 1 thread.
\end{itemize}

Largest instances have 60 aircraft, 90 periods.

\begin{enumerate}[<+->]

\item Create forecasting model based in 5000 small instances.
\item Use forecasting model to predict bounds on distance between
  maintenances: \(\hat{\mu}_{t'-t}^{lb}\), \(\hat{\mu}_{t'-t}^{ub}\).

\end{block}

\end{frame}

\begin{frame}

\begin{block}{How good is it (performance)}

Faster solutions, more solutions.

--

\includegraphics[width=0.8\linewidth]{time_performance_ordered_2tasks}

\end{block}

\end{frame}

\begin{frame}

\begin{block}{How good is it (optimality)}

For instances were an optimal solution was found (optimum degradation):
* 95\% of instances had less than 4\% gap with real optimal.

\includegraphics[width=0.8\linewidth]{quality_degradation_2tasks}

\end{block}

\end{frame}

\begin{frame}{Further steps}
\protect\hypertarget{further-steps}{}

\begin{itemize}[<+->]

\item
  \textbf{Better predictions} with better features, or predicting
  several characteristics of optimal solutions.
\item
  \textbf{Predict a distribution} and sample patterns from the
  distribution instead of predicting patterns.
\item
  \textbf{Warm-start Column Generation} with a selected subset of
  potentially good patterns.
\item
  \textbf{Automatize prediction} so it can be easily integrated in other
  problems.
\end{itemize}

\end{frame}